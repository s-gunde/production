{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with parquet files\n",
    "\n",
    "## Objective\n",
    "\n",
    "+ In this assignment, we will use the data downloaded with the module `data_manager` to create features.\n",
    "\n",
    "(11 pts total)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ This notebook assumes that price data is available to you in the environment variable `PRICE_DATA`. If you have not done so, then execute the notebook `01_materials/labs/2_data_engineering.ipynb` to create this data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variables using dotenv. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "# Load env variable\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variable `PRICE_DATA`.\n",
    "+ Use [glob](https://docs.python.org/3/library/glob.html) to find the path of all parquet files in the directory `PRICE_DATA`.\n",
    "\n",
    "(1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parquet files: 11207\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "price_data_directory='../../05_src/data/prices' # Loading PRICE_DATA \n",
    "PRICE_DATA = os.getenv('PRICE_DATA')\n",
    "\n",
    "# Use glob to find all parquet files\n",
    "parquet_files = glob(os.path.join(price_data_directory, '**/*.0.parquet'),recursive=True)\n",
    "print(\"Number of Parquet files:\", len(parquet_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ticker and using Dask, do the following:\n",
    "\n",
    "+ Add lags for variables Close and Adj_Close.\n",
    "+ Add returns based on Adjusted Close:\n",
    "    \n",
    "    - `returns`: (Adj Close / Adj Close_lag) - 1\n",
    "\n",
    "+ Add the following range: \n",
    "\n",
    "    - `hi_lo_range`: this is the day's High minus Low.\n",
    "\n",
    "+ Assign the result to `dd_feat`.\n",
    "\n",
    "(4 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Transformation, dataset is:              Date       Open       High        Low      Close  Adj Close  \\\n",
      "ticker                                                                     \n",
      "A      2000-01-03  56.330471  56.464592  48.193848  51.502148  43.463017   \n",
      "A      2000-01-04  48.730328  49.266811  46.316166  47.567955  40.142952   \n",
      "A      2000-01-05  47.389126  47.567955  43.141991  44.617310  37.652863   \n",
      "A      2000-01-06  44.080830  44.349072  41.577251  42.918453  36.219193   \n",
      "A      2000-01-07  42.247852  47.165592  42.203148  46.494991  39.237457   \n",
      "\n",
      "         Volume       sector                       subsector  year  \n",
      "ticker                                                              \n",
      "A       4674353  Health Care  Life Sciences Tools & Services  2000  \n",
      "A       4765083  Health Care  Life Sciences Tools & Services  2000  \n",
      "A       5758642  Health Care  Life Sciences Tools & Services  2000  \n",
      "A       2534434  Health Care  Life Sciences Tools & Services  2000  \n",
      "A       2819626  Health Care  Life Sciences Tools & Services  2000  \n",
      "After Transformation, dataset is:              Date       Open       High        Low      Close  Adj Close  \\\n",
      "ticker                                                                     \n",
      "HUM    2005-01-03  29.860001  29.860001  28.969999  29.160000  26.036839   \n",
      "HUM    2005-01-04  29.360001  29.590000  29.030001  29.100000  25.983265   \n",
      "HUM    2005-01-05  29.150000  29.850000  28.920000  29.700001  26.518995   \n",
      "HUM    2005-01-06  29.750000  30.299999  29.610001  29.639999  26.465424   \n",
      "HUM    2005-01-07  29.389999  29.559999  29.260000  29.420000  26.268988   \n",
      "\n",
      "         Volume       sector            subsector  year  Close_lag_1  \\\n",
      "ticker                                                                 \n",
      "HUM     1029100  Health Care  Managed Health Care  2005          NaN   \n",
      "HUM     1659200  Health Care  Managed Health Care  2005    29.160000   \n",
      "HUM     1886800  Health Care  Managed Health Care  2005    29.100000   \n",
      "HUM     1638400  Health Care  Managed Health Care  2005    29.700001   \n",
      "HUM     1194400  Health Care  Managed Health Care  2005    29.639999   \n",
      "\n",
      "         returns  positive_return  hi_lo_range  \n",
      "ticker                                          \n",
      "HUM          NaN                0     0.890001  \n",
      "HUM    -0.002058                0     0.559999  \n",
      "HUM     0.020619                1     0.930000  \n",
      "HUM    -0.002020                0     0.689999  \n",
      "HUM    -0.007422                0     0.299999  \n"
     ]
    }
   ],
   "source": [
    "dd_px = dd.read_parquet(PRICE_DATA).set_index(\"ticker\") # Loading parquet files\n",
    "print(\"Before Transformation, dataset is:\", dd_px.head(5))\n",
    "\n",
    "# Transformation\n",
    "dd_features = (dd_px.groupby('ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(Close_lag_1 = x['Close'].shift(1))\n",
    ").assign(\n",
    "    returns = lambda x: x['Close']/x['Close_lag_1'] - 1\n",
    ").assign(\n",
    "    positive_return = lambda x: (x['returns'] > 0)*1\n",
    ").assign(\n",
    "    hi_lo_range = lambda x: x['High'] - x['Low']\n",
    "))\n",
    "\n",
    "print(\"After Transformation, dataset is:\", dd_features.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Convert the Dask data frame to a pandas data frame. \n",
    "+ Add a rolling average return calculation with a window of 10 days.\n",
    "+ *Tip*: Consider using `.rolling(10).mean()`.\n",
    "\n",
    "(3 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2780684, 15)\n",
      "After Rolling Average of 10 days, the dataset is:              Date        Open        High         Low       Close   Adj Close  \\\n",
      "ticker                                                                          \n",
      "HUM    2019-01-02  283.309998  283.859985  277.230011  281.589996  269.714508   \n",
      "HUM    2019-01-03  281.399994  283.019989  269.179993  269.700012  258.325958   \n",
      "HUM    2019-01-04  272.309998  279.720001  271.070007  276.619995  264.954071   \n",
      "HUM    2019-01-07  277.000000  279.880005  274.529999  276.579987  264.915802   \n",
      "HUM    2019-01-08  278.709991  280.299988  271.209991  274.929993  263.335388   \n",
      "\n",
      "         Volume       sector            subsector  year  Close_lag_1  \\\n",
      "ticker                                                                 \n",
      "HUM     1168800  Health Care  Managed Health Care  2019          NaN   \n",
      "HUM     1330600  Health Care  Managed Health Care  2019   281.589996   \n",
      "HUM     1698900  Health Care  Managed Health Care  2019   269.700012   \n",
      "HUM     1298700  Health Care  Managed Health Care  2019   276.619995   \n",
      "HUM     1313100  Health Care  Managed Health Care  2019   276.579987   \n",
      "\n",
      "         returns  positive_return  hi_lo_range  rolling_avg_return  \n",
      "ticker                                                              \n",
      "HUM          NaN                0     6.629974                 NaN  \n",
      "HUM    -0.042224                0    13.839996                 NaN  \n",
      "HUM     0.025658                1     8.649994                 NaN  \n",
      "HUM    -0.000145                0     5.350006                 NaN  \n",
      "HUM    -0.005966                0     9.089996                 NaN  \n"
     ]
    }
   ],
   "source": [
    "# Convert transformed features set to pandas\n",
    "dd_pd = dd_features.compute()\n",
    "\n",
    "# Calculating rolling average of 10 days\n",
    "dd_pd = (dd_pd.groupby('ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(rolling_avg_return = x['returns'].rolling(10).mean())\n",
    "))\n",
    "\n",
    "print(dd_pd.shape)\n",
    "print(\"After Rolling Average of 10 days, the dataset is:\", dd_pd.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Parquet files: <class 'dask_expr._collection.DataFrame'>\n",
      "After Transformation, feature dataset: <class 'dask_expr._collection.DataFrame'>\n",
      "After converting to Pandas: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Different datatypes we used for this dataset\n",
    "\n",
    "print(\"Actual Parquet files:\", type(dd_px))\n",
    "print(\"After Transformation, feature dataset:\", type(dd_features))\n",
    "print(\"After converting to Pandas:\", type(dd_pd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please comment:\n",
    "\n",
    "+ **Was it necessary to convert to pandas to calculate the moving average return?**\n",
    "No, converting to pandas wasnâ€™t required for calculating the moving average. Dask can do this directly, which is better for large datasets. But if the data is small, using pandas can be easier.\n",
    "\n",
    "\n",
    "\n",
    "+ **Would it have been better to do it in Dask? Why?**\n",
    "Yes, doing it in Dask would be better for large datasets. Dask handles big data by working in smaller chunks, so itâ€™s faster and avoids memory issues.\n",
    "\n",
    "\n",
    "(1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_1_rubric_clean.xlsx) contains the criteria for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
